{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interacting with Jukebox",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq8uLwZCn0BV"
      },
      "source": [
        "HOW TO RUN:\n",
        "\n",
        "First, you'll need a Gmail account because the file management uses Google Drive. You'll also need a Google Colaboratory \"Colab\" Pro account ($10/month,) which gives you access to Google's high-RAM machines in the cloud. You can get to Colab Pro from the Google account settings icon.\n",
        "\n",
        "Once you have a Colab Pro account, you'll need to set your preference for high-RAM machines. Go to the Runtime menu, select \"Change runtime type,\" then selct \"High-RAM\" from the \"Runtime shape\" menu.\n",
        "\n",
        "Run all the code-block cells top-to-bottom (except as noted.) A good way of telling if the cell has completed executing is that the browser icon will turn yellow. If it's still busy, it'll be grey.\n",
        "\n",
        "Some cells will execute immediately. Others will take a few minutes, and some will take hours. The whole process will take about a day, but it doesn't require continuous attention.\n",
        "\n",
        "If you get a memory error or other crash (the arrow button will turn red,) just restart--Runtime menu/Factory reset runtime, then click the arrows again from the top. Hopefully you'll be assigned a better machine.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qEqdj8u0gdN"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAMZK4GNA_PM"
      },
      "source": [
        "Mount Google Drive. You'll be asked to enter an autorization code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPdMgaH_BPGN"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy4Rehq9ZKv_"
      },
      "source": [
        "Install Jukebox from Github."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAdFGF-bqVMY"
      },
      "source": [
        "!pip install git+https://github.com/openai/jukebox.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBcu3eEZkXzD"
      },
      "source": [
        "Import code modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taDHgk1WCC_C"
      },
      "source": [
        "import jukebox\n",
        "import torch as t\n",
        "import librosa\n",
        "import os\n",
        "from IPython.display import Audio\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
        "from jukebox.hparams import Hyperparams, setup_hparams\n",
        "from jukebox.sample import sample_single_window, _sample, \\\n",
        "                           sample_partial_window, upsample, \\\n",
        "                           load_prompts\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "rank, local_rank, device = setup_dist_from_mpi()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89FftI5kc-Az"
      },
      "source": [
        "By default, a folder for the final rendered audio files called \"samples\" will be created at the root level of your Google Drive. If you want to harvest the final files from a different folder on your Drive then you can alter the **OUTPUT_PATH** field below. You can get the path of your target folder by clicking the folder icon on the left, navigating to the folder, and selecting \"Copy path.\"\n",
        "\n",
        "<b>Note:</b> If you are going to do multiple runs of this notebook, you'll need to specify separate output folders for each run. Otherwise, the files from the runs will get intermingled.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65aR2OZxmfzq",
        "cellView": "form"
      },
      "source": [
        "OUTPUT_PATH = '/content/gdrive/MyDrive/samples' #@param {type: \"string\"}\n",
        "\n",
        "model = '5b_lyrics' # or '5b' or '1b_lyrics'\n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.n_samples = 3 if model in ('5b', '5b_lyrics') else 8\n",
        "# Specifies the directory to save the sample in.\n",
        "# We set this to the Google Drive mount point.\n",
        "hps.name = OUTPUT_PATH\n",
        "chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n",
        "max_batch_size = 3 if model in ('5b', '5b_lyrics') else 16\n",
        "hps.levels = 3\n",
        "hps.hop_fraction = [.5,.5,.125]\n",
        "\n",
        "vqvae, *priors = MODELS[model]\n",
        "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
        "top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvf-5pnjbmI1"
      },
      "source": [
        "By default, the input loop should be named \"primer.wav\" and placed in the root level of your Google Drive. But you can also use a custom directory and/or file name by changing the **INPUT_PATH** field below and copying the target path as described above.\n",
        "\n",
        "Enter the exact value of the input loop's length (in seconds) in the **INPUT_LENGTH** field, to as many decimal places as possible. This will ensure that any loops the algorithm makes are in sync with each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqqv2rJKkMXd",
        "cellView": "form"
      },
      "source": [
        "INPUT_PATH = '/content/gdrive/My Drive/primer.wav' #@param {type: \"string\"}\n",
        "INPUT_LENGTH = 8 #@param {type:\"number\"}\n",
        "\n",
        "# Prime song creation using an arbitrary audio sample.\n",
        "mode = 'primed'\n",
        "codes_file=None\n",
        "# Specify an audio file here.\n",
        "audio_file = INPUT_PATH\n",
        "# Specify how many seconds of audio to prime on.\n",
        "prompt_length_in_seconds=INPUT_LENGTH"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxZMi-S3cT2b"
      },
      "source": [
        "<font color=\"red\">Only run the cell below in the event of a memory error or other crash.</font> This will restore the process from where you left off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjRwyTDhbvf-"
      },
      "source": [
        "if os.path.exists(hps.name):\n",
        "  # Identify the lowest level generated and continue from there.\n",
        "  for level in [1, 2]:\n",
        "    data = f\"{hps.name}/level_{level}/data.pth.tar\"\n",
        "    if os.path.isfile(data):\n",
        "      mode = 'upsample'\n",
        "      codes_file = data\n",
        "      print('Upsampling from level '+str(level))\n",
        "      break\n",
        "print('mode is now '+mode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIFs2KknQC1f"
      },
      "source": [
        "Set hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp7nKnCmk1bx"
      },
      "source": [
        "sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=prompt_length_in_seconds))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYKiwkzy0Iyf"
      },
      "source": [
        "Enter the exact desired length of your final renders, to as many decimal places as possible, in the **RENDER_LENGTH** field below. This number should be an integer multiple of the input loop's length in order to generate complete loops, and less than about 90 seconds to make sure the generation process finishes in a day. Also, lengths less than 24 seconds may cause an error.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sY9aGHcZP-u",
        "cellView": "form"
      },
      "source": [
        "RENDER_LENGTH = 48 #@param {type:\"number\"}\n",
        "\n",
        "sample_length_in_seconds = RENDER_LENGTH          # Full length of musical sample to generate - we find songs in the 1 to 4 minute\n",
        "                                       # range work well, with generation time proportional to sample length.  \n",
        "                                       # This total length affects how quickly the model \n",
        "                                       # progresses through lyrics (model also generates differently\n",
        "                                       # depending on if it thinks it's in the beginning, middle, or end of sample)\n",
        "hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIiNiRAmFSGy"
      },
      "source": [
        "Enter an <a href=\"https://github.com/openai/jukebox/blob/master/jukebox/data/ids/v2_artist_ids.txt\" windown=\"_blank\">artist</a> and a <a href=\"https://github.com/openai/jukebox/blob/master/jukebox/data/ids/v2_genre_ids.txt\" windown=\"_blank\">genre</a> that you want the algorithm to model. Be sure to copy the artist name from the OpenAI Github list exactly--some of the spellings are a bit unusual. Enter any lyrics for Jukebox to sing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD0qxQeLaTR0",
        "cellView": "form"
      },
      "source": [
        "ARTIST = \"\" #@param {type: \"string\"}\n",
        "GENRE = \"\" #@param {type: \"string\"}\n",
        "LYRICS = \"\" #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "# Note: Metas can contain different prompts per sample.\n",
        "# By default, all samples use the same prompt.\n",
        "metas = [dict(artist = ARTIST,\n",
        "            genre = GENRE,\n",
        "            total_length = hps.sample_length,\n",
        "            offset = 0,\n",
        "            lyrics = LYRICS,\n",
        "            ),\n",
        "          ] * hps.n_samples\n",
        "labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]\n",
        "\n",
        "sampling_temperature = .98\n",
        "\n",
        "lower_batch_size = 16\n",
        "max_batch_size = 3 if model in ('5b', '5b_lyrics') else 16\n",
        "lower_level_chunk_size = 32\n",
        "chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n",
        "sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                        chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=0.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                         chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=sampling_temperature, fp16=True, \n",
        "                         max_batch_size=max_batch_size, chunk_size=chunk_size)]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3j0gT3HfrRD"
      },
      "source": [
        "Now we're ready to sample from the model. We'll generate the top level (2) first, followed by the first upsampling (level 1,) and then the second upsampling (level 0.) After each level, we decode to raw audio and save the audio files.   \n",
        "\n",
        "This next cell will take a while (approximately 10 minutes per 20 seconds of music sample.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a1tlvcVlHhN"
      },
      "source": [
        "if sample_hps.mode == 'ancestral':\n",
        "  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cuda') for _ in range(len(priors))]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'upsample':\n",
        "  assert sample_hps.codes_file is not None\n",
        "  # Load codes.\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  del data\n",
        "  print('Falling through to the upsample step later in the notebook.')\n",
        "elif sample_hps.mode == 'primed':\n",
        "  assert sample_hps.audio_file is not None\n",
        "  audio_files = sample_hps.audio_file.split(',')\n",
        "  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  x = load_prompts(audio_files, duration, hps)\n",
        "  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "else:\n",
        "  raise ValueError(f'Unknown sample mode {sample_hps.mode}.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJc3bQxmusc6"
      },
      "source": [
        "We are now done with the large top_prior model, and instead load the upsamplers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5VLX0zRapIm"
      },
      "source": [
        "# Set this False if you are on a local machine that has enough memory (this allows you to do the\n",
        "# lyrics alignment visualization during the upsampling stage). For a hosted runtime, \n",
        "# we'll need to go ahead and delete the top_prior if you are using the 5b_lyrics model.\n",
        "if True:\n",
        "  del top_prior\n",
        "  empty_cache()\n",
        "  top_prior=None\n",
        "upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
        "labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH_jUhGDprAt"
      },
      "source": [
        "**Note:** this next upsampling step will take several hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lkJgLolpZ6w"
      },
      "source": [
        "zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SJgBYJPri55"
      },
      "source": [
        "Now you can harvest the final rendered files in Google Drive (or listen below.) There should be three .wav files in the ```level_0``` folder, all of which are variations on the input loop. No need to harvest the files from the  ```level_1``` or  ```level_2``` folders. They are just lower resolution versions of the  ```level_0``` files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ip2PPE0rgAb"
      },
      "source": [
        "#Play render 1\n",
        "\n",
        "Audio(f'{hps.name}/level_0/item_0.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4sKwcQAntQT"
      },
      "source": [
        "#Play render 2\n",
        "\n",
        "Audio(f'{hps.name}/level_0/item_1.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bo9lHKdntb2"
      },
      "source": [
        "#Play render 3\n",
        "\n",
        "Audio(f'{hps.name}/level_0/item_2.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JAgFxytwrLG"
      },
      "source": [
        "# Clean up cache\n",
        "\n",
        "del upsamplers\n",
        "empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}