{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interacting with Jukebox",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq8uLwZCn0BV"
      },
      "source": [
        "HOW TO RUN:\n",
        "\n",
        "First, you'll need a Gmail account because the file management uses Google Drive. You'll also need a Google Colab Pro account ($10/month,) which gives you access to Google's high-RAM machines in the cloud. You can get to Colab Pro from the Google account settings icon.\n",
        "\n",
        "Once you have a Colab Pro account, you'll need to set your preference for high-RAM machines. Go to the Runtime menu, select \"Change runtime type,\" then selct \"High-RAM\" from the \"Runtime shape\" menu.\n",
        "\n",
        "Run all the code-block cells top-to-bottom (except as noted.)\n",
        "\n",
        "Some cells will execute immediately. Others will take a few minutes, and some will take hours. The whole process will take about a day, but it doesn't require continuous attention.\n",
        "\n",
        "If you get a memory error or other crash, just restart--Runtime menu/Factory reset runtime, then click the arrows again from the top. Hopefully you'll be assigned a better machine.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qEqdj8u0gdN"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAMZK4GNA_PM"
      },
      "source": [
        "Mount Google Drive. You'll be asked to enter an autorization code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPdMgaH_BPGN"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy4Rehq9ZKv_"
      },
      "source": [
        "Prepare the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAdFGF-bqVMY"
      },
      "source": [
        "!pip install git+https://github.com/openai/jukebox.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taDHgk1WCC_C"
      },
      "source": [
        "import jukebox\n",
        "import torch as t\n",
        "import librosa\n",
        "import os\n",
        "from IPython.display import Audio\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
        "from jukebox.hparams import Hyperparams, setup_hparams\n",
        "from jukebox.sample import sample_single_window, _sample, \\\n",
        "                           sample_partial_window, upsample, \\\n",
        "                           load_prompts\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "rank, local_rank, device = setup_dist_from_mpi()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89FftI5kc-Az"
      },
      "source": [
        "The line ```hps.name = '/content/gdrive/My Drive/samples'``` below determines where the algorithm will save the final rendered audio files. If you use the default setting, a folder for the renders called \"samples\" will be created at the root level of your Google Drive. If you want to harvest the final files from a different folder on your Drive then you can alter the file path.\n",
        "\n",
        "If you are going to do multiple runs of this notebook, then you'll need to specify separate output folders for each run. Otherwise, the files from the runs will get intermingled.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65aR2OZxmfzq"
      },
      "source": [
        "model = '5b_lyrics' # or '5b' or '1b_lyrics'\n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.n_samples = 3 if model in ('5b', '5b_lyrics') else 8\n",
        "# Specifies the directory to save the sample in.\n",
        "# We set this to the Google Drive mount point.\n",
        "hps.name = '/content/gdrive/My Drive/samples'\n",
        "chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n",
        "max_batch_size = 3 if model in ('5b', '5b_lyrics') else 16\n",
        "hps.levels = 3\n",
        "hps.hop_fraction = [.5,.5,.125]\n",
        "\n",
        "vqvae, *priors = MODELS[model]\n",
        "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
        "top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvf-5pnjbmI1"
      },
      "source": [
        "The ```audio_file = '/content/gdrive/My Drive/primer.wav'``` line determines where the algorithm looks to find the input loop. If you want to use the default setting, name your input loop ```primer.wav``` and put it in the root level of your Google Drive. Otherwise, you can use a custom directory or file name by changing the file path.\n",
        "\n",
        "You'll need to enter the exact value of the input loop's length to replace ```12```  where it says ```prompt_length_in_seconds=12```, to as many decimal places as possible. This will ensure that any loops the algorithm makes are in sync with each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqqv2rJKkMXd"
      },
      "source": [
        "# Prime song creation using an arbitrary audio sample.\n",
        "mode = 'primed'\n",
        "codes_file=None\n",
        "# Specify an audio file here.\n",
        "audio_file = '/content/gdrive/My Drive/primer.wav'\n",
        "# Specify how many seconds of audio to prime on.\n",
        "prompt_length_in_seconds=12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxZMi-S3cT2b"
      },
      "source": [
        "<font color=\"red\">Only run the cell below in the event of a memory error or other crash.</font> This will restore the process from where you left off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjRwyTDhbvf-"
      },
      "source": [
        "if os.path.exists(hps.name):\n",
        "  # Identify the lowest level generated and continue from there.\n",
        "  for level in [1, 2]:\n",
        "    data = f\"{hps.name}/level_{level}/data.pth.tar\"\n",
        "    if os.path.isfile(data):\n",
        "      mode = 'upsample'\n",
        "      codes_file = data\n",
        "      print('Upsampling from level '+str(level))\n",
        "      break\n",
        "print('mode is now '+mode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIFs2KknQC1f"
      },
      "source": [
        "Set hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp7nKnCmk1bx"
      },
      "source": [
        "sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=prompt_length_in_seconds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYKiwkzy0Iyf"
      },
      "source": [
        "Replace the ```50```  in ```sample_length_in_seconds = 50``` with the exact desired length of your final renders, to as many decimal places as possible. This number should be an integer multiple of the input loop's length in order to generate complete loops, and less than about 90 seconds to make sure the process finishes in a day. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sY9aGHcZP-u"
      },
      "source": [
        "sample_length_in_seconds = 50          # Full length of musical sample to generate - we find songs in the 1 to 4 minute\n",
        "                                       # range work well, with generation time proportional to sample length.  \n",
        "                                       # This total length affects how quickly the model \n",
        "                                       # progresses through lyrics (model also generates differently\n",
        "                                       # depending on if it thinks it's in the beginning, middle, or end of sample)\n",
        "hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIiNiRAmFSGy"
      },
      "source": [
        "The cell below controls the artist model, the genre model, and lyrics. Replace  ```Rick Astley``` with an <a href=\"https://github.com/openai/jukebox/blob/master/jukebox/data/ids/v2_artist_ids.txt\" windown=\"_blank\">artist</a> whose style you want the algorithm to model, and replace ```Pop```  with the <a href=\"https://github.com/openai/jukebox/blob/master/jukebox/data/ids/v2_genre_ids.txt\" windown=\"_blank\">genre</a> you want the algorithm to model. Substitute the quoted text after ```lyrics =``` with your lyrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD0qxQeLaTR0"
      },
      "source": [
        "# Note: Metas can contain different prompts per sample.\n",
        "# By default, all samples use the same prompt.\n",
        "metas = [dict(artist = \"Rick Astley\",\n",
        "            genre = \"Pop\",\n",
        "            total_length = hps.sample_length,\n",
        "            offset = 0,\n",
        "            lyrics = \"\"\"We're no strangers to love\n",
        "You know the rules and so do I\n",
        "A full commitment's what I'm thinking of\n",
        "You wouldn't get this from any other guy\n",
        "\n",
        "I just wanna tell you how I'm feeling\n",
        "Gotta make you understand\n",
        "\n",
        "Never gonna give you up\n",
        "Never gonna let you down\n",
        "Never gonna run around and desert you\n",
        "Never gonna make you cry\n",
        "Never gonna say goodbye\n",
        "Never gonna tell a lie and hurt you\n",
        "\"\"\",\n",
        "            ),\n",
        "          ] * hps.n_samples\n",
        "labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PHC1XnEfV4Y"
      },
      "source": [
        "Optionally adjust the ```sampling temperature``` (best if kept within 0.97-1.0.) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNwKyqYraTR9"
      },
      "source": [
        "sampling_temperature = .98\n",
        "\n",
        "lower_batch_size = 16\n",
        "max_batch_size = 3 if model in ('5b', '5b_lyrics') else 16\n",
        "lower_level_chunk_size = 32\n",
        "chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n",
        "sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                        chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=0.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                         chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=sampling_temperature, fp16=True, \n",
        "                         max_batch_size=max_batch_size, chunk_size=chunk_size)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3j0gT3HfrRD"
      },
      "source": [
        "Now we're ready to sample from the model. We'll generate the top level (2) first, followed by the first upsampling (level 1), and the second upsampling (0). After each level, we decode to raw audio and save the audio files.   \n",
        "\n",
        "This next cell will take a while (approximately 10 minutes per 20 seconds of music sample.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a1tlvcVlHhN"
      },
      "source": [
        "if sample_hps.mode == 'ancestral':\n",
        "  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cuda') for _ in range(len(priors))]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'upsample':\n",
        "  assert sample_hps.codes_file is not None\n",
        "  # Load codes.\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  del data\n",
        "  print('Falling through to the upsample step later in the notebook.')\n",
        "elif sample_hps.mode == 'primed':\n",
        "  assert sample_hps.audio_file is not None\n",
        "  audio_files = sample_hps.audio_file.split(',')\n",
        "  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  x = load_prompts(audio_files, duration, hps)\n",
        "  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "else:\n",
        "  raise ValueError(f'Unknown sample mode {sample_hps.mode}.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJc3bQxmusc6"
      },
      "source": [
        "We are now done with the large top_prior model, and instead load the upsamplers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5VLX0zRapIm"
      },
      "source": [
        "# Set this False if you are on a local machine that has enough memory (this allows you to do the\n",
        "# lyrics alignment visualization during the upsampling stage). For a hosted runtime, \n",
        "# we'll need to go ahead and delete the top_prior if you are using the 5b_lyrics model.\n",
        "if True:\n",
        "  del top_prior\n",
        "  empty_cache()\n",
        "  top_prior=None\n",
        "upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
        "labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH_jUhGDprAt"
      },
      "source": [
        "Please note: this next upsampling step will take several hours. As the upsampling is completed, samples will appear in the Files tab (accessible via the folder icon at the left of the notebook,) in whatever output folder was set above. Level 1 is the partially upsampled version, and then Level 0 is fully completed version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lkJgLolpZ6w"
      },
      "source": [
        "zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SJgBYJPri55"
      },
      "source": [
        "Now you can harvest the final rendered files in Google Drive (or listen below.) There should be three .wav files in the ```level_0``` folder, all of which are variations on the input loop. Don't harvest the files from the  ```level_1``` or  ```level_2``` folders. They are just lower resolution versions of the  ```level_0``` files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ip2PPE0rgAb"
      },
      "source": [
        "#Play render 1\n",
        "\n",
        "Audio(f'{hps.name}/level_0/item_0.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4sKwcQAntQT"
      },
      "source": [
        "#Play render 2\n",
        "\n",
        "Audio(f'{hps.name}/level_0/item_1.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bo9lHKdntb2"
      },
      "source": [
        "#Play render 3\n",
        "\n",
        "Audio(f'{hps.name}/level_0/item_2.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JAgFxytwrLG"
      },
      "source": [
        "# Clean up cache\n",
        "\n",
        "del upsamplers\n",
        "empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}