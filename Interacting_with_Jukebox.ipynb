{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interacting with Jukebox",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq8uLwZCn0BV"
      },
      "source": [
        "HOW TO RUN:\n",
        "\n",
        "First, you'll need a Gmail account because the file management uses Google Drive. You'll also need a Google Colab Pro account ($10/month,) which gives you access to Google's high-RAM machines in the cloud. You can get to Colab Pro from the Google account settings icon.\n",
        "\n",
        "Once you have a Colab Pro account, you'll need to set your preference for high-RAM machines. Go to the Runtime menu, select \"Change runtime type,\" then selct \"High-RAM\" from the \"Runtime shape\" menu.\n",
        "\n",
        "Run all the code-block cells top-to-bottom (except as noted.) A good way of telling if the cell has completed executing is that the browser icon will turn yellow. If it's still busy, it'll be grey.\n",
        "\n",
        "Some cells will execute immediately. Others will take a few minutes, and some will take hours. The whole process will take about a day, but it doesn't require continuous attention.\n",
        "\n",
        "If you get a memory error or other crash, just restart--Runtime menu/Factory reset runtime, then click the arrows again from the top. Hopefully you'll be assigned a better machine.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qEqdj8u0gdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890f463b-ae4a-4df8-e35f-b90d43232c1b"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-6c142ef6-cf38-80bf-c705-7bf79473b4ed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAMZK4GNA_PM"
      },
      "source": [
        "Mount Google Drive. You'll be asked to enter an autorization code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPdMgaH_BPGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82892d7-7eb0-4c1d-afa8-9c198bed19dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy4Rehq9ZKv_"
      },
      "source": [
        "Prepare the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAdFGF-bqVMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fee6253b-cbf9-4ed7-97df-88fccc1b890b"
      },
      "source": [
        "!pip install git+https://github.com/openai/jukebox.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/jukebox.git\n",
            "  Cloning https://github.com/openai/jukebox.git to /tmp/pip-req-build-85zcwpg_\n",
            "  Running command git clone -q https://github.com/openai/jukebox.git /tmp/pip-req-build-85zcwpg_\n",
            "Collecting fire==0.1.3\n",
            "  Downloading fire-0.1.3.tar.gz (33 kB)\n",
            "Collecting tqdm==4.45.0\n",
            "  Downloading tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: soundfile==0.10.3.post1 in /usr/local/lib/python3.7/dist-packages (from jukebox==1.0) (0.10.3.post1)\n",
            "Collecting unidecode==1.1.1\n",
            "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 19.2 MB/s \n",
            "\u001b[?25hCollecting numba==0.48.0\n",
            "  Downloading numba-0.48.0-1-cp37-cp37m-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 64.0 MB/s \n",
            "\u001b[?25hCollecting librosa==0.7.2\n",
            "  Downloading librosa-0.7.2.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 50.9 MB/s \n",
            "\u001b[?25hCollecting mpi4py>=3.0.0\n",
            "  Downloading mpi4py-3.1.1.tar.gz (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 65.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire==0.1.3->jukebox==1.0) (1.15.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (1.0.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.7.2->jukebox==1.0) (0.2.2)\n",
            "Collecting llvmlite<0.32.0,>=0.31.0dev0\n",
            "  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.48.0->jukebox==1.0) (57.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile==0.10.3.post1->jukebox==1.0) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile==0.10.3.post1->jukebox==1.0) (2.20)\n",
            "Building wheels for collected packages: jukebox, fire, librosa, mpi4py\n",
            "  Building wheel for jukebox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jukebox: filename=jukebox-1.0-py3-none-any.whl size=197917 sha256=347b4e4c707900675bebad7d5586bd20a7b351cc6510a46e3d0e82b762e05358\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k2_wfks2/wheels/d6/42/39/91f8a32505a445499702ae0f887769e6bb5030c42382d74ae0\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.1.3-py2.py3-none-any.whl size=49719 sha256=e0b247db120a0620a65d71340c28411d2e31fd64da1ee6dc34850dbde9fc7937\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/c5/df/d9bf8223023d31343b65f1cc57d2dc005610ebbcd2b4a5d1e7\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.7.2-py3-none-any.whl size=1612900 sha256=af84f88ebaf5af2f9bbb967fec09e26039368582a8e77cc2771c73f63c205f5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/9e/42/3224f85730f92fa2925f0b4fb6ef7f9c5431a64dfc77b95b39\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.1-cp37-cp37m-linux_x86_64.whl size=2180592 sha256=a4d362900eeb8533802b4d004fa0387fd9c097ad126f9efea53ec3f6d9ce643a\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/be/c0/2b0347be1de5cd8ca9fe67da7ec8c3fe8930fcb6b0df6f2255\n",
            "Successfully built jukebox fire librosa mpi4py\n",
            "Installing collected packages: llvmlite, numba, unidecode, tqdm, mpi4py, librosa, fire, jukebox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.0\n",
            "    Uninstalling tqdm-4.62.0:\n",
            "      Successfully uninstalled tqdm-4.62.0\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.45.0 which is incompatible.\u001b[0m\n",
            "Successfully installed fire-0.1.3 jukebox-1.0 librosa-0.7.2 llvmlite-0.31.0 mpi4py-3.1.1 numba-0.48.0 tqdm-4.45.0 unidecode-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taDHgk1WCC_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de0d53e-7e9b-4804-f1b3-fbd55961ba1b"
      },
      "source": [
        "import jukebox\n",
        "import torch as t\n",
        "import librosa\n",
        "import os\n",
        "from IPython.display import Audio\n",
        "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
        "from jukebox.hparams import Hyperparams, setup_hparams\n",
        "from jukebox.sample import sample_single_window, _sample, \\\n",
        "                           sample_partial_window, upsample, \\\n",
        "                           load_prompts\n",
        "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
        "from jukebox.utils.torch_utils import empty_cache\n",
        "rank, local_rank, device = setup_dist_from_mpi()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89FftI5kc-Az"
      },
      "source": [
        "By default, a folder for the final rendered audio files called \"samples\" will be created at the root level of your Google Drive. If you want to harvest the final files from a different folder on your Drive then you can alter the **OUTPUT_PATH** field below. You can find the path of your target folder by clicking the folder icon on the left, navigating to the folder, and selecting \"Copy path.\"\n",
        "\n",
        "<b>Note:</b> If you are going to do multiple runs of this notebook, then you'll need to specify separate output folders for each run. Otherwise, the files from the runs will get intermingled.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65aR2OZxmfzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "ccaa1843-0d27-4e50-f84e-d86834f35499"
      },
      "source": [
        "OUTPUT_PATH = '/content/gdrive/MyDrive/******test' #@param {type: \"string\"}\n",
        "\n",
        "model = '5b_lyrics' # or '5b' or '1b_lyrics'\n",
        "hps = Hyperparams()\n",
        "hps.sr = 44100\n",
        "hps.n_samples = 3 if model in ('5b', '5b_lyrics') else 8\n",
        "# Specifies the directory to save the sample in.\n",
        "# We set this to the Google Drive mount point.\n",
        "hps.name = OUTPUT_PATH\n",
        "chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n",
        "max_batch_size = 3 if model in ('5b', '5b_lyrics') else 16\n",
        "hps.levels = 3\n",
        "hps.hop_fraction = [.5,.5,.125]\n",
        "\n",
        "vqvae, *priors = MODELS[model]\n",
        "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
        "top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b/vqvae.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/vqvae.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b/vqvae.pth.tar\n",
            "0: Loading vqvae in eval mode\n",
            "Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n",
            "Level:2, Cond downsample:None, Raw to tokens:128, Sample length:1048576\n",
            "0: Converting to fp16 params\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b_lyrics/prior_level_2.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b_lyrics/prior_level_2.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b_lyrics/prior_level_2.pth.tar\n",
            "0: Loading prior in eval mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvf-5pnjbmI1"
      },
      "source": [
        "By default, the input loop should be named \"primer.wav\" and placed in the root level of your Google Drive. Otherwise, you can use a custom directory or file name by changing the **INPUT_PATH** field below and copying the target path as described above.\n",
        "\n",
        "Enter the exact value of the input loop's length (in seconds) in the **LOOP_LENGTH** field, to as many decimal places as possible. This will ensure that any loops the algorithm makes are in sync with each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqqv2rJKkMXd",
        "cellView": "form"
      },
      "source": [
        "INPUT_PATH = '/content/gdrive/My Drive/primer.wav' #@param {type: \"string\"}\n",
        "LOOP_LENGTH = 6 #@param {type:\"number\"}\n",
        "\n",
        "# Prime song creation using an arbitrary audio sample.\n",
        "mode = 'primed'\n",
        "codes_file=None\n",
        "# Specify an audio file here.\n",
        "audio_file = INPUT_PATH\n",
        "# Specify how many seconds of audio to prime on.\n",
        "prompt_length_in_seconds=LOOP_LENGTH"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxZMi-S3cT2b"
      },
      "source": [
        "<font color=\"red\">Only run the cell below in the event of a memory error or other crash.</font> This will restore the process from where you left off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjRwyTDhbvf-"
      },
      "source": [
        "if os.path.exists(hps.name):\n",
        "  # Identify the lowest level generated and continue from there.\n",
        "  for level in [1, 2]:\n",
        "    data = f\"{hps.name}/level_{level}/data.pth.tar\"\n",
        "    if os.path.isfile(data):\n",
        "      mode = 'upsample'\n",
        "      codes_file = data\n",
        "      print('Upsampling from level '+str(level))\n",
        "      break\n",
        "print('mode is now '+mode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIFs2KknQC1f"
      },
      "source": [
        "Set hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp7nKnCmk1bx"
      },
      "source": [
        "sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=prompt_length_in_seconds))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYKiwkzy0Iyf"
      },
      "source": [
        "Enter the exact desired length of your final renders, to as many decimal places as possible, in the **RENDER_LENGTH** field below. This number should be an integer multiple of the input loop's length in order to generate complete loops, and less than about 90 seconds to make sure the generation process finishes in a day. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sY9aGHcZP-u",
        "cellView": "form"
      },
      "source": [
        "RENDER_LENGTH = 48 #@param {type:\"number\"}\n",
        "\n",
        "sample_length_in_seconds = RENDER_LENGTH          # Full length of musical sample to generate - we find songs in the 1 to 4 minute\n",
        "                                       # range work well, with generation time proportional to sample length.  \n",
        "                                       # This total length affects how quickly the model \n",
        "                                       # progresses through lyrics (model also generates differently\n",
        "                                       # depending on if it thinks it's in the beginning, middle, or end of sample)\n",
        "hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIiNiRAmFSGy"
      },
      "source": [
        "Enter an <a href=\"https://github.com/openai/jukebox/blob/master/jukebox/data/ids/v2_artist_ids.txt\" windown=\"_blank\">artist</a> whose style you want the algorithm to model, and a <a href=\"https://github.com/openai/jukebox/blob/master/jukebox/data/ids/v2_genre_ids.txt\" windown=\"_blank\">genre</a> you want the algorithm to model. Be sure to copy the artist name from OpenAI Github list exactly--some of the spellings are a bit unusual. Enter any lyrics for Jukebox to sing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD0qxQeLaTR0",
        "cellView": "form"
      },
      "source": [
        "ARTIST = \"james_taylor\" #@param {type: \"string\"}\n",
        "GENRE = \"alternative\" #@param {type: \"string\"}\n",
        "LYRICS = \"blah blah\" #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "# Note: Metas can contain different prompts per sample.\n",
        "# By default, all samples use the same prompt.\n",
        "metas = [dict(artist = ARTIST,\n",
        "            genre = GENRE,\n",
        "            total_length = hps.sample_length,\n",
        "            offset = 0,\n",
        "            lyrics = LYRICS,\n",
        "            ),\n",
        "          ] * hps.n_samples\n",
        "labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]\n",
        "\n",
        "sampling_temperature = .98\n",
        "\n",
        "lower_batch_size = 16\n",
        "max_batch_size = 3 if model in ('5b', '5b_lyrics') else 16\n",
        "lower_level_chunk_size = 32\n",
        "chunk_size = 16 if model in ('5b', '5b_lyrics') else 32\n",
        "sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                        chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=0.99, fp16=True, max_batch_size=lower_batch_size,\n",
        "                         chunk_size=lower_level_chunk_size),\n",
        "                    dict(temp=sampling_temperature, fp16=True, \n",
        "                         max_batch_size=max_batch_size, chunk_size=chunk_size)]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3j0gT3HfrRD"
      },
      "source": [
        "Now we're ready to sample from the model. We'll generate the top level (2) first, followed by the first upsampling (level 1,) and then the second upsampling (level 0.) After each level, we decode to raw audio and save the audio files.   \n",
        "\n",
        "This next cell will take a while (approximately 10 minutes per 20 seconds of music sample.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a1tlvcVlHhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6eafac-b1a2-442e-83f7-8864604dbe5b"
      },
      "source": [
        "if sample_hps.mode == 'ancestral':\n",
        "  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cuda') for _ in range(len(priors))]\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "elif sample_hps.mode == 'upsample':\n",
        "  assert sample_hps.codes_file is not None\n",
        "  # Load codes.\n",
        "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
        "  zs = [z.cuda() for z in data['zs']]\n",
        "  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
        "  del data\n",
        "  print('Falling through to the upsample step later in the notebook.')\n",
        "elif sample_hps.mode == 'primed':\n",
        "  assert sample_hps.audio_file is not None\n",
        "  audio_files = sample_hps.audio_file.split(',')\n",
        "  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
        "  x = load_prompts(audio_files, duration, hps)\n",
        "  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n",
        "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
        "else:\n",
        "  raise ValueError(f'Unknown sample mode {sample_hps.mode}.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling level 2\n",
            "Sampling 8192 tokens for [0,8192]. Conditioning on 2067 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "130/130 [00:23<00:00,  5.50it/s]\n",
            "6125/6125 [08:40<00:00, 11.78it/s]\n",
            "Sampling 8192 tokens for [1024,9216]. Conditioning on 7168 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "448/448 [01:48<00:00,  4.14it/s]\n",
            "1024/1024 [01:43<00:00,  9.87it/s]\n",
            "Sampling 8192 tokens for [2048,10240]. Conditioning on 7168 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "448/448 [01:48<00:00,  4.14it/s]\n",
            "1024/1024 [01:43<00:00,  9.87it/s]\n",
            "Sampling 8192 tokens for [3072,11264]. Conditioning on 7168 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "448/448 [01:48<00:00,  4.14it/s]\n",
            "1024/1024 [01:43<00:00,  9.88it/s]\n",
            "Sampling 8192 tokens for [4096,12288]. Conditioning on 7168 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "448/448 [01:48<00:00,  4.14it/s]\n",
            "1024/1024 [01:43<00:00,  9.88it/s]\n",
            "Sampling 8192 tokens for [5120,13312]. Conditioning on 7168 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "448/448 [01:48<00:00,  4.14it/s]\n",
            "1024/1024 [01:43<00:00,  9.88it/s]\n",
            "Sampling 8192 tokens for [6144,14336]. Conditioning on 7168 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "448/448 [01:48<00:00,  4.14it/s]\n",
            "1024/1024 [01:43<00:00,  9.88it/s]\n",
            "Sampling 8192 tokens for [7168,15360]. Conditioning on 7168 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "448/448 [01:48<00:00,  4.14it/s]\n",
            "1024/1024 [01:43<00:00,  9.88it/s]\n",
            "Sampling 8192 tokens for [8192,16384]. Conditioning on 7168 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "448/448 [01:48<00:00,  4.14it/s]\n",
            "1024/1024 [01:43<00:00,  9.87it/s]\n",
            "Sampling 8192 tokens for [8345,16537]. Conditioning on 8039 tokens\n",
            "Primed sampling 3 samples with temp=0.98, top_k=0, top_p=0.0\n",
            "503/503 [02:06<00:00,  3.96it/s]\n",
            "153/153 [00:16<00:00,  9.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJc3bQxmusc6"
      },
      "source": [
        "We are now done with the large top_prior model, and instead load the upsamplers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5VLX0zRapIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff3ed44-5d5b-48ab-fd51-d3e4fe82a8cd"
      },
      "source": [
        "# Set this False if you are on a local machine that has enough memory (this allows you to do the\n",
        "# lyrics alignment visualization during the upsampling stage). For a hosted runtime, \n",
        "# we'll need to go ahead and delete the top_prior if you are using the 5b_lyrics model.\n",
        "if True:\n",
        "  del top_prior\n",
        "  empty_cache()\n",
        "  top_prior=None\n",
        "upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
        "labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conditioning on 1 above level(s)\n",
            "Checkpointing convs\n",
            "Checkpointing convs\n",
            "Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n",
            "Level:0, Cond downsample:4, Raw to tokens:8, Sample length:65536\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b/prior_level_0.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_0.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b/prior_level_0.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "Conditioning on 1 above level(s)\n",
            "Checkpointing convs\n",
            "Checkpointing convs\n",
            "Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_artist_ids.txt\n",
            "Loading artist IDs from /usr/local/lib/python3.7/dist-packages/jukebox/data/ids/v2_genre_ids.txt\n",
            "Level:1, Cond downsample:4, Raw to tokens:32, Sample length:262144\n",
            "Downloading from azure\n",
            "Running  wget -O /root/.cache/jukebox/models/5b/prior_level_1.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/prior_level_1.pth.tar\n",
            "Restored from /root/.cache/jukebox/models/5b/prior_level_1.pth.tar\n",
            "0: Loading prior in eval mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH_jUhGDprAt"
      },
      "source": [
        "**Note:** this next upsampling step will take several hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lkJgLolpZ6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f562d5a0-85d5-4e08-a12a-cc920c9728a9"
      },
      "source": [
        "zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling level 1\n",
            "Sampling 8192 tokens for [0,8192]. Conditioning on 8192 tokens\n",
            "Sampling 8192 tokens for [4096,12288]. Conditioning on 4172 tokens\n",
            "Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "131/131 [00:10<00:00, 12.06it/s]\n",
            "4020/4020 [03:29<00:00, 19.22it/s]\n",
            "Sampling 8192 tokens for [8192,16384]. Conditioning on 4096 tokens\n",
            "Primed sampling 3 samples with temp=0.99, top_k=0, top_p=0.0\n",
            "128/128 [00:10<00:00, 12.48it/s]\n",
            "438/4096 [00:21<03:09, 19.34it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SJgBYJPri55"
      },
      "source": [
        "Now you can harvest the final rendered files in Google Drive (or listen below.) There should be three .wav files in the ```level_0``` folder, all of which are variations on the input loop. Don't harvest the files from the  ```level_1``` or  ```level_2``` folders. They are just lower resolution versions of the  ```level_0``` files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ip2PPE0rgAb"
      },
      "source": [
        "#Play render 1\n",
        "\n",
        "Audio(f'{hps.name}/level_0/item_0.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4sKwcQAntQT"
      },
      "source": [
        "#Play render 2\n",
        "\n",
        "Audio(f'{hps.name}/level_0/item_1.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bo9lHKdntb2"
      },
      "source": [
        "#Play render 3\n",
        "\n",
        "Audio(f'{hps.name}/level_0/item_2.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JAgFxytwrLG"
      },
      "source": [
        "# Clean up cache\n",
        "\n",
        "del upsamplers\n",
        "empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}